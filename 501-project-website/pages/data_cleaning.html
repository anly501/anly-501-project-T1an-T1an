<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>Document</title>
</head>
<body>
    <h1>Data Cleaning by R</h1>
    <p>
        <ul>
            <li><a href='https://github.com/anly501/anly-501-project-T1an-T1an/tree/main/codes/02-data-cleaning'>R code for data cleaning</a></li>
            <p>
                In the original dataset, there are two columns that contain time information. Obviously the second column about time is unnecessary, 
                so I removed it. Meanwhile, the first time column contains a lot of unnecessary information. 
                I removed the extra information by splitting and deleting. 
                With these steps I got the initial cleaned up data. Data type of the column date was also modified from char to date.<br />
                <br />
            <p>
                The initial data looks like the picture below.<br />
                <br />
            </p>
                <td>
                    <img src="../images/initial _data.png" width="800" height="125">
                    
              </td>

              <p>
                After modifing these two colums, the initial data looks more clean and neat.
              </p>
            
              <td>
                <img src="../images/initial _data_1st_clean.png" width="800" height="125">
                
            </td>
            <p>
                But I also needed the stability of the price over time, so I calculated the rolling mean to 
                get the closing price of the cryptocurrencies of different types for 20 days or 5 days. 
                20 days average closing price is the variable M20 and 5 days average closing price is the 
                variable M5. These two variables can be used to determine the These two variables can be
                 used as important indicators to determine the price stability of cryptocurrencies.

            </p>

              <td>
                <img src="../images/final_data_currency.png" width="550" height="500">
                
          </td>

            <p>
                From the table above we can get all the values we need at the moment. 
                It is worth noting that for M20 and M5 columns contain some of the NA values. However, 
                these values cannot be removed. Since M20 is the average of cryptocurrency closing prices 
                over 20 days, the values from the first row to the 19th row are NA. Similarly, in M5, 
                the values from the first row to the fifth row are NA.
            </p>
            </p>
        </ul>
    </p>


    <h1>Data Cleaning by Python</h1>
    <p>
        <li><a href='https://github.com/anly501/anly-501-project-T1an-T1an/tree/main/codes/02-data-cleaning'>Python code for data cleaning</a></li>
        <p>
            The initial data from twitter is a jason format and itlooks like the plot below:<br />
        </p>
        <td>
            <img src="../images/raw_twitter_data.png" width="900" height="400">
            <!-- local path    file:///Users/jingdayang/anly-501-project-T1an-T1an/501-project-website/images/BTC%20data%20from%20FTX%20exchange.png -->
      </td>
        <p>
            This data set does contain a lot of information, but some information is not not necessary. Only text is the most important category.
            Hence all other information is removed except text.<br />
        </p>
        <td>
            <img src="../images/twitter_data_1st_clean.png" width="366" height="333">
            
      </td>
        <p>
            After doing this, splitting each tweet into individual words.
        </p>
        <td>
            <img src="../images/twitter_data_2nd_clean.png" width="300" height="333">
            
      </td>
        <p>
            In all words, some words and punctuation are redundant, so I removed punctuation and words with less than three letters.
        </p>
        <td>
            <img src="../images/twitter_data_3rd_clean.png" width="250" height="333">
            
      </td>
        </p>

        <p>
            The number of occurrences of different keywords is shown below.
        </p>

        <td>
            <img src="../images/word_occ.png" width="250" height="333">
            
      </td>

      <p>
        Because of the large number of words, 
        I randomly selected 20 words for the CountVectorizer step. 
        By using CountVectorizer, I derived the MAX COUNT matrix and ONE_HOT_ENCODED matrix.

      </p>
      <p>
        MAX COUNT matrix
      </p>
      <td>
        <img src="../images/max_matrix.png" width="500" height="50">
        
  </td>
    <p>
        ONE_HOT_ENCODED matrix
    </p>

    <td>
        <img src="../images/Hot_encoded_matrix.png" width="450" height="500">
        
  </td>
    <p>
        The final correlation table looks like this.
    
    </p>
    <td>
        <img src="../images/corr_table.png" width="900" height="350">
        
  </td>
    </p>

</body>
</html>